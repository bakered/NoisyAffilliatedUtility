---

title: We don't know what's good for us
author: ''
slug: []
categories: []
tags: []
---


My actions can cause one state of the world to occur rather than another. There is a set of realisable worlds (the ones I can realise by my actions). 

Some states of the world are preferable to other states of the world.

It is possible to order the set of realisable worlds from the worst realisable world to the best one.

If I were omnipotent I would act such that the best of possible worlds was realised. However, I do not know which of my actions cause which worlds and I cannot fully comprehend any of the worlds anyway. I can never say with 100% confidence that action A will lead to a more preferable world than action B.

This applies even to simple decisions such as whether I should eat an apple or an orange. 




```r
summary(Orange)
```

```
##  Tree       age         circumference  
##  3:7   Min.   : 118.0   Min.   : 30.0  
##  1:7   1st Qu.: 484.0   1st Qu.: 65.5  
##  5:7   Median :1004.0   Median :115.0  
##  2:7   Mean   : 922.1   Mean   :115.9  
##  4:7   3rd Qu.:1372.0   3rd Qu.:161.5  
##        Max.   :1582.0   Max.   :214.0
```


```
## Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =
## "none")` instead.
```

<img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" />
